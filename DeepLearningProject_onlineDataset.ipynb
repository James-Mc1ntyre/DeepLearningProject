{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Motor Imagery Deep Learning project <br>\n",
    "By: James McIntyre and John McLinden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/device:GPU:0\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_probability as tfp\n",
    "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "from keras import layers, losses\n",
    "import mne \n",
    "mne.utils.set_config('MNE_USE_CUDA', 'true')  \n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import minmax_scale\n",
    "physical_devices = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(tf.test.gpu_device_name())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load data\n",
    "Load saved epochs and labels from preprocessing step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath = os.getcwd()\n",
    "\n",
    "data = np.load(filepath + '\\\\RecordedProjectData\\\\preprocessedOnlineDataset_EpochsAndLabels.npz')\n",
    "x_train = data['training_epochs']\n",
    "y_train = data['training_labels']\n",
    "x_test = data['testing_epochs']\n",
    "y_test = data['testing_labels']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create one-hot encoding for labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Usign their one-hot encoding function\n",
    "def to_one_hot(y, by_sub=False):\n",
    "    if by_sub:\n",
    "        new_array = np.array([\"nan\" for nan in range(len(y))])\n",
    "        for index, label in enumerate(y):\n",
    "            new_array[index] = ''.join([i for i in label if not i.isdigit()])\n",
    "    else:\n",
    "        new_array = y.copy()\n",
    "    total_labels = np.unique(new_array)\n",
    "    mapping = {}\n",
    "    for x in range(len(total_labels)):\n",
    "        mapping[total_labels[x]] = x\n",
    "    for x in range(len(new_array)):\n",
    "        new_array[x] = mapping[new_array[x]]\n",
    "\n",
    "    return tf.keras.utils.to_categorical(new_array)\n",
    "        \n",
    "#Transform y to one-hot-encoding\n",
    "# enc = onehot\n",
    "y_test_valid_OH = to_one_hot(y_test)\n",
    "y_train_OH = to_one_hot(y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape data then apply MinMax scaling, in the same way that the CNN was trained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape for scaling\n",
    "x_train_reshapedForScaling = x_train.reshape(x_train.shape[0], x_train.shape[1] * x_train.shape[2])\n",
    "x_test_valid_reshapedForScaling = x_test.reshape(x_test.shape[0], x_test.shape[1] * x_test.shape[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale train and test separately\n",
    "x_train_scaled = minmax_scale(x_train_reshapedForScaling, axis=2)\n",
    "x_test_valid_scaled = minmax_scale(x_test_valid_reshapedForScaling, axis=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape after scaling, reshape training data after SMOTE\n",
    "x_test_valid_reshaped = x_test_valid_scaled.reshape(x_test_valid_scaled.shape[0], int(x_test_valid_scaled.shape[1]/2),2).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create Val/Test split from test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create Validation/test\n",
    "x_valid_reshaped, x_test_reshaped, y_valid_OH, y_test_OH = train_test_split(x_test_valid_reshaped,\n",
    "                                                    y_test_valid_OH,\n",
    "                                                    stratify=y_test_valid_OH,\n",
    "                                                    test_size=0.50,\n",
    "                                                    random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply SMOTE for data augmentation<br>\n",
    "Only apply to training set <br>\n",
    "Does not apply for online dataset, only for the limited recorded dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # smote\n",
    "# from imblearn.over_sampling import SMOTE\n",
    "# sm = SMOTE(random_state=42)\n",
    "# x_train_smote, y_train_OH_smote = sm.fit_resample(x_train_scaled, y_train_OH)\n",
    "# print('classes count')\n",
    "# print ('before oversampling = {}'.format(y_train_OH.sum(axis=0)))\n",
    "# print ('after oversampling = {}'.format(y_train_OH_smote.sum(axis=0)))\n",
    "\n",
    "# no smote\n",
    "x_train_smote, y_train_OH_smote = x_train_scaled, y_train_OH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reshape training data after SMOTE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reshaped = x_train_smote.reshape(x_train_smote.shape[0], int(x_train_smote.shape[1]/2),2).astype(np.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train CNN architecture on new dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up and train a CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HopefullNet(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Original HopeFullNet\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_shape = (640,2)):\n",
    "        super(HopefullNet, self).__init__()\n",
    "        self.inp_shape = inp_shape\n",
    "\n",
    "        self.kernel_size_0 = 20\n",
    "        self.kernel_size_1 = 6\n",
    "        self.drop_rate = 0.5\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv1D(filters=32,\n",
    "                                            kernel_size=self.kernel_size_0,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"same\",\n",
    "                                            input_shape=self.inp_shape)\n",
    "        self.batch_n_1 = tf.keras.layers.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv1D(filters=32,\n",
    "                                            kernel_size=self.kernel_size_0,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.batch_n_2 = tf.keras.layers.BatchNormalization()\n",
    "        self.spatial_drop_1 = tf.keras.layers.SpatialDropout1D(self.drop_rate)\n",
    "        self.conv3 = tf.keras.layers.Conv1D(filters=32,\n",
    "                                            kernel_size=self.kernel_size_1,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.avg_pool1 = tf.keras.layers.AvgPool1D(pool_size=2)\n",
    "        self.conv4 = tf.keras.layers.Conv1D(filters=32,\n",
    "                                            kernel_size=self.kernel_size_1,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.spatial_drop_2 = tf.keras.layers.SpatialDropout1D(self.drop_rate)\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(296, activation='relu')\n",
    "        self.dropout1 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.dense2 = tf.keras.layers.Dense(148, activation='relu')\n",
    "        self.dropout2 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.dense3 = tf.keras.layers.Dense(74, activation='relu')\n",
    "        self.dropout3 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.out = tf.keras.layers.Dense(4, activation='softmax')\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        conv1 = self.conv1(input_tensor)\n",
    "        batch_n_1 = self.batch_n_1(conv1)\n",
    "        conv2 = self.conv2(batch_n_1)\n",
    "        batch_n_2 = self.batch_n_2(conv2)\n",
    "        spatial_drop_1 = self.spatial_drop_1(batch_n_2)\n",
    "        conv3 = self.conv3(spatial_drop_1)\n",
    "        avg_pool1 = self.avg_pool1(conv3)\n",
    "        conv4 = self.conv4(avg_pool1)\n",
    "        spatial_drop_2 = self.spatial_drop_2(conv4)\n",
    "        flat = self.flat(spatial_drop_2)\n",
    "        dense1 = self.dense1(flat)\n",
    "        dropout1 = self.dropout1(dense1)\n",
    "        dense2 = self.dense2(dropout1)\n",
    "        dropout2 = self.dropout2(dense2)\n",
    "        return self.out(dropout2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "model = HopefullNet()\n",
    "\n",
    "model.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Where to save model\n",
    "modelPath = filepath + r'\\models\\OnlineDatasetTraainedModel.h5'\n",
    "\n",
    "# build callback list\n",
    "checkpoint = ModelCheckpoint( # set model saving checkpoints\n",
    "    modelPath, # set path to save model weights\n",
    "    monitor='val_loss', # set monitor metrics\n",
    "    verbose=1, # set training verbosity\n",
    "    save_best_only=True, # set if want to save only best weights\n",
    "    save_weights_only=True, # set if you want to save only model weights\n",
    "    mode='auto', # set if save min or max in metrics\n",
    "    save_freq='epoch' # interval between checkpoints\n",
    "    )\n",
    "\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss', # set monitor metrics\n",
    "    min_delta=0.00001, # set minimum metrics delta\n",
    "    patience=6, # number of epochs to stop training\n",
    "    restore_best_weights=True, # set if use best weights or last weights\n",
    "    )\n",
    "callbacksList = [checkpoint, earlystopping] # build callbacks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.7575 - accuracy: 0.2793\n",
      "Epoch 1: val_loss improved from inf to 1.38595, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 6s 52ms/step - loss: 1.7575 - accuracy: 0.2793 - val_loss: 1.3860 - val_accuracy: 0.2624\n",
      "Epoch 2/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.5578 - accuracy: 0.2558\n",
      "Epoch 2: val_loss did not improve from 1.38595\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 1.5556 - accuracy: 0.2548 - val_loss: 1.3862 - val_accuracy: 0.2525\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.4928 - accuracy: 0.2613\n",
      "Epoch 3: val_loss did not improve from 1.38595\n",
      "78/78 [==============================] - 3s 45ms/step - loss: 1.4928 - accuracy: 0.2613 - val_loss: 1.3866 - val_accuracy: 0.2437\n",
      "Epoch 4/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.4525 - accuracy: 0.2675\n",
      "Epoch 4: val_loss improved from 1.38595 to 1.38569, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 46ms/step - loss: 1.4510 - accuracy: 0.2690 - val_loss: 1.3857 - val_accuracy: 0.2525\n",
      "Epoch 5/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.4347 - accuracy: 0.2649\n",
      "Epoch 5: val_loss improved from 1.38569 to 1.38353, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 45ms/step - loss: 1.4352 - accuracy: 0.2664 - val_loss: 1.3835 - val_accuracy: 0.2800\n",
      "Epoch 6/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.4328 - accuracy: 0.2623\n",
      "Epoch 6: val_loss improved from 1.38353 to 1.38305, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 45ms/step - loss: 1.4336 - accuracy: 0.2625 - val_loss: 1.3831 - val_accuracy: 0.2889\n",
      "Epoch 7/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.4175 - accuracy: 0.2870\n",
      "Epoch 7: val_loss did not improve from 1.38305\n",
      "78/78 [==============================] - 3s 44ms/step - loss: 1.4166 - accuracy: 0.2857 - val_loss: 1.3836 - val_accuracy: 0.2800\n",
      "Epoch 8/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.4194 - accuracy: 0.2779\n",
      "Epoch 8: val_loss did not improve from 1.38305\n",
      "78/78 [==============================] - 3s 44ms/step - loss: 1.4206 - accuracy: 0.2767 - val_loss: 1.3847 - val_accuracy: 0.2811\n",
      "Epoch 9/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3985 - accuracy: 0.2688\n",
      "Epoch 9: val_loss did not improve from 1.38305\n",
      "78/78 [==============================] - 3s 44ms/step - loss: 1.3999 - accuracy: 0.2677 - val_loss: 1.3840 - val_accuracy: 0.2834\n",
      "Epoch 10/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.4093 - accuracy: 0.2714\n",
      "Epoch 10: val_loss did not improve from 1.38305\n",
      "78/78 [==============================] - 3s 43ms/step - loss: 1.4091 - accuracy: 0.2690 - val_loss: 1.3834 - val_accuracy: 0.2966\n",
      "Epoch 11/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3865 - accuracy: 0.2792\n",
      "Epoch 11: val_loss improved from 1.38305 to 1.38303, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 3s 45ms/step - loss: 1.3883 - accuracy: 0.2780 - val_loss: 1.3830 - val_accuracy: 0.2911\n",
      "Epoch 12/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3935 - accuracy: 0.2740\n",
      "Epoch 12: val_loss improved from 1.38303 to 1.38231, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 46ms/step - loss: 1.3932 - accuracy: 0.2728 - val_loss: 1.3823 - val_accuracy: 0.2867\n",
      "Epoch 13/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3855 - accuracy: 0.2831\n",
      "Epoch 13: val_loss did not improve from 1.38231\n",
      "78/78 [==============================] - 3s 44ms/step - loss: 1.3860 - accuracy: 0.2819 - val_loss: 1.3828 - val_accuracy: 0.2624\n",
      "Epoch 14/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3810 - accuracy: 0.2857\n",
      "Epoch 14: val_loss did not improve from 1.38231\n",
      "78/78 [==============================] - 3s 44ms/step - loss: 1.3811 - accuracy: 0.2857 - val_loss: 1.3825 - val_accuracy: 0.2767\n",
      "Epoch 15/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3877 - accuracy: 0.2909\n",
      "Epoch 15: val_loss improved from 1.38231 to 1.38198, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 46ms/step - loss: 1.3873 - accuracy: 0.2921 - val_loss: 1.3820 - val_accuracy: 0.2955\n",
      "Epoch 16/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3851 - accuracy: 0.2766\n",
      "Epoch 16: val_loss improved from 1.38198 to 1.38139, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 46ms/step - loss: 1.3847 - accuracy: 0.2767 - val_loss: 1.3814 - val_accuracy: 0.2778\n",
      "Epoch 17/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3754 - accuracy: 0.2831\n",
      "Epoch 17: val_loss improved from 1.38139 to 1.37832, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 46ms/step - loss: 1.3752 - accuracy: 0.2819 - val_loss: 1.3783 - val_accuracy: 0.2933\n",
      "Epoch 18/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3683 - accuracy: 0.3130\n",
      "Epoch 18: val_loss improved from 1.37832 to 1.37680, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.3697 - accuracy: 0.3115 - val_loss: 1.3768 - val_accuracy: 0.2977\n",
      "Epoch 19/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3692 - accuracy: 0.3117\n",
      "Epoch 19: val_loss did not improve from 1.37680\n",
      "78/78 [==============================] - 3s 45ms/step - loss: 1.3699 - accuracy: 0.3102 - val_loss: 1.3779 - val_accuracy: 0.3208\n",
      "Epoch 20/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3741 - accuracy: 0.2870\n",
      "Epoch 20: val_loss improved from 1.37680 to 1.37481, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 45ms/step - loss: 1.3741 - accuracy: 0.2857 - val_loss: 1.3748 - val_accuracy: 0.3208\n",
      "Epoch 21/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3756 - accuracy: 0.2948\n",
      "Epoch 21: val_loss improved from 1.37481 to 1.37473, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 47ms/step - loss: 1.3775 - accuracy: 0.2921 - val_loss: 1.3747 - val_accuracy: 0.2966\n",
      "Epoch 22/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3780 - accuracy: 0.3104\n",
      "Epoch 22: val_loss improved from 1.37473 to 1.37351, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.3787 - accuracy: 0.3102 - val_loss: 1.3735 - val_accuracy: 0.3153\n",
      "Epoch 23/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3822 - accuracy: 0.2831\n",
      "Epoch 23: val_loss improved from 1.37351 to 1.37317, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 46ms/step - loss: 1.3814 - accuracy: 0.2857 - val_loss: 1.3732 - val_accuracy: 0.3175\n",
      "Epoch 24/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3679 - accuracy: 0.3182\n",
      "Epoch 24: val_loss improved from 1.37317 to 1.37110, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.3676 - accuracy: 0.3179 - val_loss: 1.3711 - val_accuracy: 0.3054\n",
      "Epoch 25/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3492 - accuracy: 0.3182\n",
      "Epoch 25: val_loss improved from 1.37110 to 1.36888, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 1.3485 - accuracy: 0.3179 - val_loss: 1.3689 - val_accuracy: 0.3230\n",
      "Epoch 26/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3620 - accuracy: 0.3026\n",
      "Epoch 26: val_loss improved from 1.36888 to 1.36079, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 1.3620 - accuracy: 0.3024 - val_loss: 1.3608 - val_accuracy: 0.3164\n",
      "Epoch 27/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3549 - accuracy: 0.3286\n",
      "Epoch 27: val_loss did not improve from 1.36079\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.3538 - accuracy: 0.3282 - val_loss: 1.3609 - val_accuracy: 0.3252\n",
      "Epoch 28/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3566 - accuracy: 0.3312\n",
      "Epoch 28: val_loss improved from 1.36079 to 1.35892, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 47ms/step - loss: 1.3565 - accuracy: 0.3295 - val_loss: 1.3589 - val_accuracy: 0.3252\n",
      "Epoch 29/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3412 - accuracy: 0.3668\n",
      "Epoch 29: val_loss improved from 1.35892 to 1.35621, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 51ms/step - loss: 1.3412 - accuracy: 0.3668 - val_loss: 1.3562 - val_accuracy: 0.3330\n",
      "Epoch 30/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3440 - accuracy: 0.3295\n",
      "Epoch 30: val_loss did not improve from 1.35621\n",
      "78/78 [==============================] - 4s 53ms/step - loss: 1.3440 - accuracy: 0.3295 - val_loss: 1.3569 - val_accuracy: 0.3087\n",
      "Epoch 31/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3202 - accuracy: 0.3681\n",
      "Epoch 31: val_loss improved from 1.35621 to 1.35389, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 54ms/step - loss: 1.3202 - accuracy: 0.3681 - val_loss: 1.3539 - val_accuracy: 0.3186\n",
      "Epoch 32/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3355 - accuracy: 0.3501\n",
      "Epoch 32: val_loss improved from 1.35389 to 1.35276, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 52ms/step - loss: 1.3355 - accuracy: 0.3501 - val_loss: 1.3528 - val_accuracy: 0.3275\n",
      "Epoch 33/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3080 - accuracy: 0.3805\n",
      "Epoch 33: val_loss improved from 1.35276 to 1.34643, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 56ms/step - loss: 1.3078 - accuracy: 0.3784 - val_loss: 1.3464 - val_accuracy: 0.3142\n",
      "Epoch 34/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3186 - accuracy: 0.3552\n",
      "Epoch 34: val_loss did not improve from 1.34643\n",
      "78/78 [==============================] - 4s 54ms/step - loss: 1.3186 - accuracy: 0.3552 - val_loss: 1.3494 - val_accuracy: 0.3418\n",
      "Epoch 35/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3217 - accuracy: 0.3688\n",
      "Epoch 35: val_loss did not improve from 1.34643\n",
      "78/78 [==============================] - 3s 44ms/step - loss: 1.3231 - accuracy: 0.3681 - val_loss: 1.3509 - val_accuracy: 0.3264\n",
      "Epoch 36/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3181 - accuracy: 0.3623\n",
      "Epoch 36: val_loss improved from 1.34643 to 1.34373, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 2s 31ms/step - loss: 1.3185 - accuracy: 0.3604 - val_loss: 1.3437 - val_accuracy: 0.3352\n",
      "Epoch 37/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3019 - accuracy: 0.4196\n",
      "Epoch 37: val_loss improved from 1.34373 to 1.33766, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 55ms/step - loss: 1.3019 - accuracy: 0.4196 - val_loss: 1.3377 - val_accuracy: 0.3230\n",
      "Epoch 38/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2950 - accuracy: 0.4041\n",
      "Epoch 38: val_loss improved from 1.33766 to 1.33662, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 50ms/step - loss: 1.2950 - accuracy: 0.4041 - val_loss: 1.3366 - val_accuracy: 0.3396\n",
      "Epoch 39/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2782 - accuracy: 0.4003\n",
      "Epoch 39: val_loss did not improve from 1.33662\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.2782 - accuracy: 0.4003 - val_loss: 1.3395 - val_accuracy: 0.3396\n",
      "Epoch 40/100\n",
      "76/78 [============================>.] - ETA: 0s - loss: 1.2671 - accuracy: 0.4211\n",
      "Epoch 40: val_loss improved from 1.33662 to 1.33496, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 2s 31ms/step - loss: 1.2638 - accuracy: 0.4260 - val_loss: 1.3350 - val_accuracy: 0.3440\n",
      "Epoch 41/100\n",
      "76/78 [============================>.] - ETA: 0s - loss: 1.2565 - accuracy: 0.4316\n",
      "Epoch 41: val_loss improved from 1.33496 to 1.32788, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 3s 37ms/step - loss: 1.2598 - accuracy: 0.4299 - val_loss: 1.3279 - val_accuracy: 0.3550\n",
      "Epoch 42/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.2358 - accuracy: 0.4610\n",
      "Epoch 42: val_loss improved from 1.32788 to 1.31814, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 1.2364 - accuracy: 0.4620 - val_loss: 1.3181 - val_accuracy: 0.3649\n",
      "Epoch 43/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.2072 - accuracy: 0.4584\n",
      "Epoch 43: val_loss improved from 1.31814 to 1.31273, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 1.2125 - accuracy: 0.4556 - val_loss: 1.3127 - val_accuracy: 0.3782\n",
      "Epoch 44/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.2438 - accuracy: 0.4195\n",
      "Epoch 44: val_loss did not improve from 1.31273\n",
      "78/78 [==============================] - 4s 51ms/step - loss: 1.2403 - accuracy: 0.4208 - val_loss: 1.3224 - val_accuracy: 0.3561\n",
      "Epoch 45/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.1868 - accuracy: 0.4801\n",
      "Epoch 45: val_loss did not improve from 1.31273\n",
      "78/78 [==============================] - 4s 51ms/step - loss: 1.1868 - accuracy: 0.4801 - val_loss: 1.3317 - val_accuracy: 0.3462\n",
      "Epoch 46/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.1904 - accuracy: 0.4714\n",
      "Epoch 46: val_loss did not improve from 1.31273\n",
      "78/78 [==============================] - 4s 51ms/step - loss: 1.1896 - accuracy: 0.4723 - val_loss: 1.3179 - val_accuracy: 0.3385\n",
      "Epoch 47/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.1645 - accuracy: 0.4749\n",
      "Epoch 47: val_loss improved from 1.31273 to 1.31121, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 50ms/step - loss: 1.1645 - accuracy: 0.4749 - val_loss: 1.3112 - val_accuracy: 0.3473\n",
      "Epoch 48/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.1554 - accuracy: 0.4955\n",
      "Epoch 48: val_loss improved from 1.31121 to 1.30841, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 50ms/step - loss: 1.1554 - accuracy: 0.4955 - val_loss: 1.3084 - val_accuracy: 0.3473\n",
      "Epoch 49/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.1396 - accuracy: 0.4968\n",
      "Epoch 49: val_loss did not improve from 1.30841\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.1396 - accuracy: 0.4968 - val_loss: 1.3212 - val_accuracy: 0.3671\n",
      "Epoch 50/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.1412 - accuracy: 0.5122\n",
      "Epoch 50: val_loss improved from 1.30841 to 1.30833, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 52ms/step - loss: 1.1412 - accuracy: 0.5122 - val_loss: 1.3083 - val_accuracy: 0.3594\n",
      "Epoch 51/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.0863 - accuracy: 0.5148\n",
      "Epoch 51: val_loss did not improve from 1.30833\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 1.0863 - accuracy: 0.5148 - val_loss: 1.3202 - val_accuracy: 0.3716\n",
      "Epoch 52/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.0810 - accuracy: 0.5338\n",
      "Epoch 52: val_loss improved from 1.30833 to 1.29950, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 51ms/step - loss: 1.0838 - accuracy: 0.5315 - val_loss: 1.2995 - val_accuracy: 0.3760\n",
      "Epoch 53/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.0860 - accuracy: 0.5264\n",
      "Epoch 53: val_loss did not improve from 1.29950\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 1.0860 - accuracy: 0.5264 - val_loss: 1.3038 - val_accuracy: 0.3793\n",
      "Epoch 54/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.0573 - accuracy: 0.5650\n",
      "Epoch 54: val_loss did not improve from 1.29950\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 1.0573 - accuracy: 0.5650 - val_loss: 1.3254 - val_accuracy: 0.3660\n",
      "Epoch 55/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.0213 - accuracy: 0.5403\n",
      "Epoch 55: val_loss did not improve from 1.29950\n",
      "78/78 [==============================] - 4s 50ms/step - loss: 1.0245 - accuracy: 0.5380 - val_loss: 1.3228 - val_accuracy: 0.3671\n",
      "Epoch 56/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.0007 - accuracy: 0.5597\n",
      "Epoch 56: val_loss improved from 1.29950 to 1.29927, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\OnlineDatasetTraainedModel.h5\n",
      "78/78 [==============================] - 4s 51ms/step - loss: 1.0019 - accuracy: 0.5598 - val_loss: 1.2993 - val_accuracy: 0.3738\n",
      "Epoch 57/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.0101 - accuracy: 0.5883\n",
      "Epoch 57: val_loss did not improve from 1.29927\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.0094 - accuracy: 0.5882 - val_loss: 1.3192 - val_accuracy: 0.3705\n",
      "Epoch 58/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.9645 - accuracy: 0.5896\n",
      "Epoch 58: val_loss did not improve from 1.29927\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 0.9638 - accuracy: 0.5894 - val_loss: 1.3053 - val_accuracy: 0.3771\n",
      "Epoch 59/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.9515 - accuracy: 0.6052\n",
      "Epoch 59: val_loss did not improve from 1.29927\n",
      "78/78 [==============================] - 4s 46ms/step - loss: 0.9507 - accuracy: 0.6062 - val_loss: 1.3203 - val_accuracy: 0.3738\n",
      "Epoch 60/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.9542 - accuracy: 0.6036\n",
      "Epoch 60: val_loss did not improve from 1.29927\n",
      "78/78 [==============================] - 4s 46ms/step - loss: 0.9542 - accuracy: 0.6036 - val_loss: 1.3250 - val_accuracy: 0.3627\n",
      "Epoch 61/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.9510 - accuracy: 0.6088\n",
      "Epoch 61: val_loss did not improve from 1.29927\n",
      "78/78 [==============================] - 4s 49ms/step - loss: 0.9510 - accuracy: 0.6088 - val_loss: 1.3228 - val_accuracy: 0.3649\n",
      "Epoch 62/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.8734 - accuracy: 0.6519\n",
      "Epoch 62: val_loss did not improve from 1.29927\n",
      "78/78 [==============================] - 3s 45ms/step - loss: 0.8695 - accuracy: 0.6551 - val_loss: 1.3405 - val_accuracy: 0.3936\n"
     ]
    }
   ],
   "source": [
    "hist = model.fit(x_train_reshaped, y_train_OH_smote, epochs=100, batch_size=10,\n",
    "                validation_data=(x_valid_reshaped, y_valid_OH), callbacks=callbacksList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f3abe0e880>"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(hist.history['accuracy'], color = 'b')\n",
    "ax.plot(hist.history['val_accuracy'], linestyle=':', color = 'b')\n",
    "ax.set_ylabel(\"Accuracy\", color = 'b')\n",
    "ax.set_ylim([0,1])\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(hist.history['loss'],  color = 'r')\n",
    "ax2.plot(hist.history['val_loss'], linestyle=':',  color = 'r')\n",
    "ax2.set_ylabel(\"Loss (cross-entropy)\",  color = 'r')\n",
    "fig.legend(['accuracy','val_accuracy','loss','val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN autoencoder\n",
    "\n",
    "Set up the CNN autoencoder <br>\n",
    "set up decoder with transpose convolutional layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create an autoencoder for feature learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 296\n",
    "\n",
    "class MyEncoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Based on Original HopeFullNet\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_shape = (640,2)):\n",
    "        super(MyEncoder, self).__init__()\n",
    "        self.inp_shape = inp_shape\n",
    "\n",
    "        self.kernel_size_0 = 20\n",
    "        self.kernel_size_1 = 6\n",
    "        self.drop_rate = 0.5\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv1D(filters=32,\n",
    "                                            kernel_size=self.kernel_size_0,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"same\",\n",
    "                                            input_shape=self.inp_shape)\n",
    "        self.batch_n_1 = tfp.bijectors.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv1D(filters=32,\n",
    "                                            kernel_size=self.kernel_size_0,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.batch_n_2 = tfp.bijectors.BatchNormalization()\n",
    "        self.spatial_drop_1 = tf.keras.layers.SpatialDropout1D(self.drop_rate)\n",
    "        self.conv3 = tf.keras.layers.Conv1D(filters=32,\n",
    "                                            kernel_size=self.kernel_size_1,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.avg_pool1 = tf.keras.layers.AvgPool1D(pool_size=2)\n",
    "        self.conv4 = tf.keras.layers.Conv1D(filters=32,\n",
    "                                            kernel_size=self.kernel_size_1,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.spatial_drop_2 = tf.keras.layers.SpatialDropout1D(self.drop_rate)\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.out = tf.keras.layers.Dense(296, activation='relu')\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        conv1 = self.conv1(input_tensor)\n",
    "        batch_n_1 = self.batch_n_1(conv1)\n",
    "        conv2 = self.conv2(batch_n_1)\n",
    "        batch_n_2 = self.batch_n_2(conv2)\n",
    "        spatial_drop_1 = self.spatial_drop_1(batch_n_2)\n",
    "        conv3 = self.conv3(spatial_drop_1)\n",
    "        avg_pool1 = self.avg_pool1(conv3)\n",
    "        conv4 = self.conv4(avg_pool1)\n",
    "        spatial_drop_2 = self.spatial_drop_2(conv4)\n",
    "        flat = self.flat(spatial_drop_2)\n",
    "        return self.out(flat)\n",
    "\n",
    "class MyDecoder(tf.keras.Model):\n",
    "    \"\"\"\n",
    "    Based on Original HopeFullNet\n",
    "    \"\"\"\n",
    "    def __init__(self, inp_shape = (296,)):\n",
    "        super(MyDecoder, self).__init__()\n",
    "        self.inp_shape = inp_shape\n",
    "\n",
    "        self.kernel_size_0 = 20\n",
    "        self.kernel_size_1 = 6\n",
    "        self.drop_rate = 0.5\n",
    "\n",
    "        self.conv1 = tf.keras.layers.Conv1DTranspose(filters=32,\n",
    "                                            kernel_size=self.kernel_size_0,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"same\",\n",
    "                                            input_shape=self.inp_shape)\n",
    "        self.batch_n_1 = tfp.bijectors.BatchNormalization()\n",
    "        self.conv2 = tf.keras.layers.Conv1DTranspose(filters=32,\n",
    "                                            kernel_size=self.kernel_size_0,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.batch_n_2 = tfp.bijectors.BatchNormalization()\n",
    "        self.spatial_drop_1 = tf.keras.layers.SpatialDropout1D(self.drop_rate)\n",
    "        self.conv3 = tf.keras.layers.Conv1DTranspose(filters=32,\n",
    "                                            kernel_size=self.kernel_size_1,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.avg_pool1 = tf.keras.layers.AvgPool1D(pool_size=2)\n",
    "        self.conv4 = tf.keras.layers.Conv1DTranspose(filters=32,\n",
    "                                            kernel_size=self.kernel_size_1,\n",
    "                                            activation='relu',\n",
    "                                            padding= \"valid\")\n",
    "        self.spatial_drop_2 = tf.keras.layers.SpatialDropout1D(self.drop_rate)\n",
    "        self.reshape1 = tf.keras.layers.Reshape((148,2))\n",
    "        self.flat = tf.keras.layers.Flatten()\n",
    "        self.dense1 = tf.keras.layers.Dense(296, activation='relu')\n",
    "        self.dropout1 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.dense2 = tf.keras.layers.Dense(148, activation='relu')\n",
    "        self.dropout2 = tf.keras.layers.Dropout(self.drop_rate)\n",
    "        self.out = tf.keras.layers.Dense(1280, activation='relu')\n",
    "        self.reshape2 = tf.keras.layers.Reshape((640,2))\n",
    "\n",
    "    def call(self, input_tensor):\n",
    "        dense1 = self.dense1(input_tensor)\n",
    "        flat = self.reshape1(dense1)\n",
    "        spatial_drop_2 = self.spatial_drop_2(flat)\n",
    "        conv4 = self.conv4(spatial_drop_2)\n",
    "        avg_pool1 = self.avg_pool1(conv4)\n",
    "        conv3 = self.conv3(avg_pool1)\n",
    "        spatial_drop_1 = self.spatial_drop_1(conv3)\n",
    "        batch_n_2 = self.batch_n_2(spatial_drop_1)\n",
    "        conv2 = self.conv2(batch_n_2)\n",
    "        batch_n_1 = self.batch_n_1(conv2)\n",
    "        conv1 = self.conv1(batch_n_1)\n",
    "        flat1 = self.flat(conv1)\n",
    "        last = self.out(flat1)\n",
    "        return self.reshape2(last)\n",
    "\n",
    "\n",
    "class Autoencoder(tf.keras.models.Model):\n",
    "  def __init__(self, latent_dim):\n",
    "    super(Autoencoder, self).__init__()\n",
    "    self.latent_dim = latent_dim   \n",
    "    self.encoder = MyEncoder()\n",
    "    self.decoder = MyDecoder()\n",
    "\n",
    "  def call(self, x):\n",
    "    encoded = self.encoder(x)\n",
    "    decoded = self.decoder(encoded)\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compile the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder = Autoencoder(latent_dim)\n",
    "autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n",
    "\n",
    "modelPath = filepath+'\\\\models\\\\autoencoderOnlineDataModel.h5'\n",
    "\n",
    "# build callback list\n",
    "checkpoint = ModelCheckpoint( # set model saving checkpoints\n",
    "    modelPath, # set path to save model weights\n",
    "    monitor='val_loss', # set monitor metrics\n",
    "    verbose=1, # set training verbosity\n",
    "    save_best_only=True, # set if want to save only best weights\n",
    "    save_weights_only=True, # set if you want to save only model weights\n",
    "    mode='auto', # set if save min or max in metrics\n",
    "    save_freq='epoch' # interval between checkpoints\n",
    "    )\n",
    "\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss', # set monitor metrics\n",
    "    min_delta=0.00001, # set minimum metrics delta\n",
    "    patience=10, # number of epochs to stop training\n",
    "    restore_best_weights=True, # set if use best weights or last weights\n",
    "    )\n",
    "callbacksList = [checkpoint, earlystopping] # build callbacks list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train the autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0890\n",
      "Epoch 1: val_loss improved from inf to 0.04451, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 10s 79ms/step - loss: 0.0886 - val_loss: 0.0445\n",
      "Epoch 2/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0446\n",
      "Epoch 2: val_loss did not improve from 0.04451\n",
      "78/78 [==============================] - 6s 73ms/step - loss: 0.0446 - val_loss: 0.0456\n",
      "Epoch 3/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0450\n",
      "Epoch 3: val_loss did not improve from 0.04451\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0450 - val_loss: 0.0450\n",
      "Epoch 4/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0448\n",
      "Epoch 4: val_loss did not improve from 0.04451\n",
      "78/78 [==============================] - 5s 68ms/step - loss: 0.0449 - val_loss: 0.0451\n",
      "Epoch 5/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0446\n",
      "Epoch 5: val_loss improved from 0.04451 to 0.04421, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 73ms/step - loss: 0.0446 - val_loss: 0.0442\n",
      "Epoch 6/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0449\n",
      "Epoch 6: val_loss did not improve from 0.04421\n",
      "78/78 [==============================] - 5s 68ms/step - loss: 0.0449 - val_loss: 0.0442\n",
      "Epoch 7/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0446\n",
      "Epoch 7: val_loss did not improve from 0.04421\n",
      "78/78 [==============================] - 5s 68ms/step - loss: 0.0445 - val_loss: 0.0444\n",
      "Epoch 8/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0444\n",
      "Epoch 8: val_loss did not improve from 0.04421\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.0444 - val_loss: 0.0443\n",
      "Epoch 9/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0442\n",
      "Epoch 9: val_loss improved from 0.04421 to 0.04409, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 74ms/step - loss: 0.0442 - val_loss: 0.0441\n",
      "Epoch 10/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0445\n",
      "Epoch 10: val_loss improved from 0.04409 to 0.04402, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 72ms/step - loss: 0.0445 - val_loss: 0.0440\n",
      "Epoch 11/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0444\n",
      "Epoch 11: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0444 - val_loss: 0.0443\n",
      "Epoch 12/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0445\n",
      "Epoch 12: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 6s 72ms/step - loss: 0.0445 - val_loss: 0.0440\n",
      "Epoch 13/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0442\n",
      "Epoch 13: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 6s 73ms/step - loss: 0.0442 - val_loss: 0.0443\n",
      "Epoch 14/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 14: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 5s 68ms/step - loss: 0.0443 - val_loss: 0.0447\n",
      "Epoch 15/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0444\n",
      "Epoch 15: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 5s 68ms/step - loss: 0.0444 - val_loss: 0.0443\n",
      "Epoch 16/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 16: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0442 - val_loss: 0.0442\n",
      "Epoch 17/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0442\n",
      "Epoch 17: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.0442 - val_loss: 0.0441\n",
      "Epoch 18/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 18: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0443 - val_loss: 0.0443\n",
      "Epoch 19/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 19: val_loss did not improve from 0.04402\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.0443 - val_loss: 0.0446\n",
      "Epoch 20/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 20: val_loss improved from 0.04402 to 0.04399, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 71ms/step - loss: 0.0441 - val_loss: 0.0440\n",
      "Epoch 21/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 21: val_loss did not improve from 0.04399\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0441 - val_loss: 0.0441\n",
      "Epoch 22/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 22: val_loss did not improve from 0.04399\n",
      "78/78 [==============================] - 5s 63ms/step - loss: 0.0441 - val_loss: 0.0441\n",
      "Epoch 23/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 23: val_loss did not improve from 0.04399\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0442 - val_loss: 0.0444\n",
      "Epoch 24/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 24: val_loss did not improve from 0.04399\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0443 - val_loss: 0.0448\n",
      "Epoch 25/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0442\n",
      "Epoch 25: val_loss did not improve from 0.04399\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.0442 - val_loss: 0.0441\n",
      "Epoch 26/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 26: val_loss did not improve from 0.04399\n",
      "78/78 [==============================] - 6s 72ms/step - loss: 0.0441 - val_loss: 0.0444\n",
      "Epoch 27/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 27: val_loss improved from 0.04399 to 0.04392, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 81ms/step - loss: 0.0442 - val_loss: 0.0439\n",
      "Epoch 28/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 28: val_loss did not improve from 0.04392\n",
      "78/78 [==============================] - 6s 82ms/step - loss: 0.0442 - val_loss: 0.0441\n",
      "Epoch 29/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 29: val_loss improved from 0.04392 to 0.04388, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 83ms/step - loss: 0.0443 - val_loss: 0.0439\n",
      "Epoch 30/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 30: val_loss did not improve from 0.04388\n",
      "78/78 [==============================] - 6s 79ms/step - loss: 0.0441 - val_loss: 0.0440\n",
      "Epoch 31/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 31: val_loss did not improve from 0.04388\n",
      "78/78 [==============================] - 6s 77ms/step - loss: 0.0442 - val_loss: 0.0444\n",
      "Epoch 32/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 32: val_loss did not improve from 0.04388\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0441 - val_loss: 0.0440\n",
      "Epoch 33/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0439\n",
      "Epoch 33: val_loss did not improve from 0.04388\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0439 - val_loss: 0.0440\n",
      "Epoch 34/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0440\n",
      "Epoch 34: val_loss did not improve from 0.04388\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0440 - val_loss: 0.0446\n",
      "Epoch 35/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0442\n",
      "Epoch 35: val_loss did not improve from 0.04388\n",
      "78/78 [==============================] - 6s 73ms/step - loss: 0.0442 - val_loss: 0.0440\n",
      "Epoch 36/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0440\n",
      "Epoch 36: val_loss improved from 0.04388 to 0.04377, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0440 - val_loss: 0.0438\n",
      "Epoch 37/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 37: val_loss improved from 0.04377 to 0.04372, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 86ms/step - loss: 0.0443 - val_loss: 0.0437\n",
      "Epoch 38/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 38: val_loss did not improve from 0.04372\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0443 - val_loss: 0.0444\n",
      "Epoch 39/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 39: val_loss improved from 0.04372 to 0.04362, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 90ms/step - loss: 0.0441 - val_loss: 0.0436\n",
      "Epoch 40/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0437\n",
      "Epoch 40: val_loss did not improve from 0.04362\n",
      "78/78 [==============================] - 7s 86ms/step - loss: 0.0437 - val_loss: 0.0439\n",
      "Epoch 41/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0441\n",
      "Epoch 41: val_loss did not improve from 0.04362\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0441 - val_loss: 0.0448\n",
      "Epoch 42/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0438\n",
      "Epoch 42: val_loss improved from 0.04362 to 0.04353, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 83ms/step - loss: 0.0438 - val_loss: 0.0435\n",
      "Epoch 43/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0438\n",
      "Epoch 43: val_loss did not improve from 0.04353\n",
      "78/78 [==============================] - 6s 78ms/step - loss: 0.0438 - val_loss: 0.0436\n",
      "Epoch 44/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0438\n",
      "Epoch 44: val_loss did not improve from 0.04353\n",
      "78/78 [==============================] - 6s 76ms/step - loss: 0.0438 - val_loss: 0.0436\n",
      "Epoch 45/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0443\n",
      "Epoch 45: val_loss did not improve from 0.04353\n",
      "78/78 [==============================] - 6s 76ms/step - loss: 0.0443 - val_loss: 0.0438\n",
      "Epoch 46/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0437\n",
      "Epoch 46: val_loss did not improve from 0.04353\n",
      "78/78 [==============================] - 6s 74ms/step - loss: 0.0438 - val_loss: 0.0437\n",
      "Epoch 47/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0440\n",
      "Epoch 47: val_loss improved from 0.04353 to 0.04353, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 77ms/step - loss: 0.0440 - val_loss: 0.0435\n",
      "Epoch 48/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0438\n",
      "Epoch 48: val_loss did not improve from 0.04353\n",
      "78/78 [==============================] - 6s 77ms/step - loss: 0.0438 - val_loss: 0.0436\n",
      "Epoch 49/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0439\n",
      "Epoch 49: val_loss did not improve from 0.04353\n",
      "78/78 [==============================] - 6s 81ms/step - loss: 0.0439 - val_loss: 0.0436\n",
      "Epoch 50/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0438\n",
      "Epoch 50: val_loss did not improve from 0.04353\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0438 - val_loss: 0.0436\n",
      "Epoch 51/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0437\n",
      "Epoch 51: val_loss did not improve from 0.04353\n",
      "78/78 [==============================] - 6s 74ms/step - loss: 0.0437 - val_loss: 0.0439\n",
      "Epoch 52/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0438\n",
      "Epoch 52: val_loss improved from 0.04353 to 0.04344, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 77ms/step - loss: 0.0438 - val_loss: 0.0434\n",
      "Epoch 53/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 53: val_loss did not improve from 0.04344\n",
      "78/78 [==============================] - 6s 78ms/step - loss: 0.0435 - val_loss: 0.0443\n",
      "Epoch 54/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 54: val_loss improved from 0.04344 to 0.04333, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 79ms/step - loss: 0.0436 - val_loss: 0.0433\n",
      "Epoch 55/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 55: val_loss did not improve from 0.04333\n",
      "78/78 [==============================] - 6s 82ms/step - loss: 0.0436 - val_loss: 0.0434\n",
      "Epoch 56/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 56: val_loss did not improve from 0.04333\n",
      "78/78 [==============================] - 6s 79ms/step - loss: 0.0435 - val_loss: 0.0434\n",
      "Epoch 57/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0434\n",
      "Epoch 57: val_loss improved from 0.04333 to 0.04325, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 83ms/step - loss: 0.0434 - val_loss: 0.0432\n",
      "Epoch 58/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 58: val_loss did not improve from 0.04325\n",
      "78/78 [==============================] - 6s 83ms/step - loss: 0.0435 - val_loss: 0.0436\n",
      "Epoch 59/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0436\n",
      "Epoch 59: val_loss did not improve from 0.04325\n",
      "78/78 [==============================] - 6s 81ms/step - loss: 0.0436 - val_loss: 0.0434\n",
      "Epoch 60/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 60: val_loss did not improve from 0.04325\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0435 - val_loss: 0.0437\n",
      "Epoch 61/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0437\n",
      "Epoch 61: val_loss did not improve from 0.04325\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0437 - val_loss: 0.0435\n",
      "Epoch 62/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 62: val_loss did not improve from 0.04325\n",
      "78/78 [==============================] - 6s 78ms/step - loss: 0.0435 - val_loss: 0.0436\n",
      "Epoch 63/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 63: val_loss improved from 0.04325 to 0.04306, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0435 - val_loss: 0.0431\n",
      "Epoch 64/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0433\n",
      "Epoch 64: val_loss did not improve from 0.04306\n",
      "78/78 [==============================] - 6s 77ms/step - loss: 0.0433 - val_loss: 0.0433\n",
      "Epoch 65/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0435\n",
      "Epoch 65: val_loss did not improve from 0.04306\n",
      "78/78 [==============================] - 6s 78ms/step - loss: 0.0435 - val_loss: 0.0432\n",
      "Epoch 66/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0434\n",
      "Epoch 66: val_loss did not improve from 0.04306\n",
      "78/78 [==============================] - 6s 79ms/step - loss: 0.0434 - val_loss: 0.0433\n",
      "Epoch 67/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0434\n",
      "Epoch 67: val_loss did not improve from 0.04306\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0434 - val_loss: 0.0432\n",
      "Epoch 68/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0432\n",
      "Epoch 68: val_loss did not improve from 0.04306\n",
      "78/78 [==============================] - 6s 74ms/step - loss: 0.0432 - val_loss: 0.0431\n",
      "Epoch 69/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0432\n",
      "Epoch 69: val_loss did not improve from 0.04306\n",
      "78/78 [==============================] - 6s 73ms/step - loss: 0.0432 - val_loss: 0.0441\n",
      "Epoch 70/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0430\n",
      "Epoch 70: val_loss improved from 0.04306 to 0.04284, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 77ms/step - loss: 0.0430 - val_loss: 0.0428\n",
      "Epoch 71/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0428\n",
      "Epoch 71: val_loss improved from 0.04284 to 0.04274, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 82ms/step - loss: 0.0428 - val_loss: 0.0427\n",
      "Epoch 72/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0430\n",
      "Epoch 72: val_loss did not improve from 0.04274\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0430 - val_loss: 0.0433\n",
      "Epoch 73/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0429\n",
      "Epoch 73: val_loss did not improve from 0.04274\n",
      "78/78 [==============================] - 6s 77ms/step - loss: 0.0429 - val_loss: 0.0428\n",
      "Epoch 74/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0427\n",
      "Epoch 74: val_loss improved from 0.04274 to 0.04241, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 86ms/step - loss: 0.0427 - val_loss: 0.0424\n",
      "Epoch 75/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0426\n",
      "Epoch 75: val_loss did not improve from 0.04241\n",
      "78/78 [==============================] - 6s 79ms/step - loss: 0.0426 - val_loss: 0.0431\n",
      "Epoch 76/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0425\n",
      "Epoch 76: val_loss improved from 0.04241 to 0.04239, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 86ms/step - loss: 0.0425 - val_loss: 0.0424\n",
      "Epoch 77/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0425\n",
      "Epoch 77: val_loss did not improve from 0.04239\n",
      "78/78 [==============================] - 6s 81ms/step - loss: 0.0425 - val_loss: 0.0424\n",
      "Epoch 78/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0427\n",
      "Epoch 78: val_loss improved from 0.04239 to 0.04234, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 84ms/step - loss: 0.0427 - val_loss: 0.0423\n",
      "Epoch 79/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Epoch 79: val_loss did not improve from 0.04234\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0424 - val_loss: 0.0424\n",
      "Epoch 80/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0426\n",
      "Epoch 80: val_loss did not improve from 0.04234\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0426 - val_loss: 0.0428\n",
      "Epoch 81/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0425\n",
      "Epoch 81: val_loss improved from 0.04234 to 0.04227, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 83ms/step - loss: 0.0425 - val_loss: 0.0423\n",
      "Epoch 82/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0422\n",
      "Epoch 82: val_loss did not improve from 0.04227\n",
      "78/78 [==============================] - 6s 79ms/step - loss: 0.0422 - val_loss: 0.0426\n",
      "Epoch 83/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 83: val_loss improved from 0.04227 to 0.04204, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0422 - val_loss: 0.0420\n",
      "Epoch 84/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 84: val_loss improved from 0.04204 to 0.04195, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0422 - val_loss: 0.0419\n",
      "Epoch 85/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 85: val_loss did not improve from 0.04195\n",
      "78/78 [==============================] - 6s 83ms/step - loss: 0.0422 - val_loss: 0.0420\n",
      "Epoch 86/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 86: val_loss did not improve from 0.04195\n",
      "78/78 [==============================] - 6s 82ms/step - loss: 0.0422 - val_loss: 0.0420\n",
      "Epoch 87/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0423\n",
      "Epoch 87: val_loss did not improve from 0.04195\n",
      "78/78 [==============================] - 6s 76ms/step - loss: 0.0423 - val_loss: 0.0421\n",
      "Epoch 88/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 88: val_loss did not improve from 0.04195\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0421 - val_loss: 0.0421\n",
      "Epoch 89/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 89: val_loss did not improve from 0.04195\n",
      "78/78 [==============================] - 6s 78ms/step - loss: 0.0421 - val_loss: 0.0420\n",
      "Epoch 90/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0424\n",
      "Epoch 90: val_loss did not improve from 0.04195\n",
      "78/78 [==============================] - 6s 77ms/step - loss: 0.0424 - val_loss: 0.0421\n",
      "Epoch 91/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0422\n",
      "Epoch 91: val_loss did not improve from 0.04195\n",
      "78/78 [==============================] - 6s 79ms/step - loss: 0.0422 - val_loss: 0.0422\n",
      "Epoch 92/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 92: val_loss improved from 0.04195 to 0.04131, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 83ms/step - loss: 0.0421 - val_loss: 0.0413\n",
      "Epoch 93/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 93: val_loss did not improve from 0.04131\n",
      "78/78 [==============================] - 6s 82ms/step - loss: 0.0415 - val_loss: 0.0416\n",
      "Epoch 94/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 94: val_loss did not improve from 0.04131\n",
      "78/78 [==============================] - 6s 79ms/step - loss: 0.0415 - val_loss: 0.0414\n",
      "Epoch 95/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0416\n",
      "Epoch 95: val_loss did not improve from 0.04131\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0416 - val_loss: 0.0417\n",
      "Epoch 96/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 96: val_loss did not improve from 0.04131\n",
      "78/78 [==============================] - 6s 74ms/step - loss: 0.0415 - val_loss: 0.0420\n",
      "Epoch 97/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0421\n",
      "Epoch 97: val_loss did not improve from 0.04131\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0421 - val_loss: 0.0419\n",
      "Epoch 98/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 98: val_loss improved from 0.04131 to 0.04120, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 78ms/step - loss: 0.0415 - val_loss: 0.0412\n",
      "Epoch 99/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0414\n",
      "Epoch 99: val_loss did not improve from 0.04120\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0414 - val_loss: 0.0414\n",
      "Epoch 100/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0414\n",
      "Epoch 100: val_loss did not improve from 0.04120\n",
      "78/78 [==============================] - 6s 81ms/step - loss: 0.0414 - val_loss: 0.0415\n",
      "Epoch 101/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 101: val_loss did not improve from 0.04120\n",
      "78/78 [==============================] - 6s 76ms/step - loss: 0.0415 - val_loss: 0.0414\n",
      "Epoch 102/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0415\n",
      "Epoch 102: val_loss did not improve from 0.04120\n",
      "78/78 [==============================] - 6s 78ms/step - loss: 0.0415 - val_loss: 0.0416\n",
      "Epoch 103/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0412\n",
      "Epoch 103: val_loss improved from 0.04120 to 0.04094, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 80ms/step - loss: 0.0412 - val_loss: 0.0409\n",
      "Epoch 104/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0411\n",
      "Epoch 104: val_loss improved from 0.04094 to 0.04092, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 76ms/step - loss: 0.0411 - val_loss: 0.0409\n",
      "Epoch 105/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0411\n",
      "Epoch 105: val_loss did not improve from 0.04092\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0411 - val_loss: 0.0411\n",
      "Epoch 106/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0410\n",
      "Epoch 106: val_loss improved from 0.04092 to 0.04064, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 86ms/step - loss: 0.0410 - val_loss: 0.0406\n",
      "Epoch 107/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0406\n",
      "Epoch 107: val_loss improved from 0.04064 to 0.04037, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 84ms/step - loss: 0.0406 - val_loss: 0.0404\n",
      "Epoch 108/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0405\n",
      "Epoch 108: val_loss improved from 0.04037 to 0.04037, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 7s 90ms/step - loss: 0.0405 - val_loss: 0.0404\n",
      "Epoch 109/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0405\n",
      "Epoch 109: val_loss did not improve from 0.04037\n",
      "78/78 [==============================] - 6s 73ms/step - loss: 0.0405 - val_loss: 0.0404\n",
      "Epoch 110/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0406\n",
      "Epoch 110: val_loss did not improve from 0.04037\n",
      "78/78 [==============================] - 6s 73ms/step - loss: 0.0406 - val_loss: 0.0404\n",
      "Epoch 111/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0405\n",
      "Epoch 111: val_loss did not improve from 0.04037\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0405 - val_loss: 0.0408\n",
      "Epoch 112/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0408\n",
      "Epoch 112: val_loss did not improve from 0.04037\n",
      "78/78 [==============================] - 6s 75ms/step - loss: 0.0408 - val_loss: 0.0405\n",
      "Epoch 113/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0406\n",
      "Epoch 113: val_loss did not improve from 0.04037\n",
      "78/78 [==============================] - 5s 68ms/step - loss: 0.0406 - val_loss: 0.0408\n",
      "Epoch 114/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0406\n",
      "Epoch 114: val_loss improved from 0.04037 to 0.04027, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 6s 72ms/step - loss: 0.0406 - val_loss: 0.0403\n",
      "Epoch 115/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 115: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 5s 71ms/step - loss: 0.0403 - val_loss: 0.0404\n",
      "Epoch 116/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0404\n",
      "Epoch 116: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 6s 72ms/step - loss: 0.0404 - val_loss: 0.0403\n",
      "Epoch 117/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0404\n",
      "Epoch 117: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.0404 - val_loss: 0.0403\n",
      "Epoch 118/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0404\n",
      "Epoch 118: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.0404 - val_loss: 0.0407\n",
      "Epoch 119/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0404\n",
      "Epoch 119: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0404 - val_loss: 0.0405\n",
      "Epoch 120/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0405\n",
      "Epoch 120: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.0404 - val_loss: 0.0404\n",
      "Epoch 121/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0404\n",
      "Epoch 121: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0404 - val_loss: 0.0406\n",
      "Epoch 122/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0404\n",
      "Epoch 122: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0404 - val_loss: 0.0407\n",
      "Epoch 123/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0404\n",
      "Epoch 123: val_loss did not improve from 0.04027\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0404 - val_loss: 0.0404\n",
      "Epoch 124/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 124: val_loss improved from 0.04027 to 0.04009, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.0403 - val_loss: 0.0401\n",
      "Epoch 125/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0403\n",
      "Epoch 125: val_loss did not improve from 0.04009\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.0403 - val_loss: 0.0401\n",
      "Epoch 126/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0403\n",
      "Epoch 126: val_loss improved from 0.04009 to 0.03990, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.0403 - val_loss: 0.0399\n",
      "Epoch 127/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0401\n",
      "Epoch 127: val_loss did not improve from 0.03990\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0401 - val_loss: 0.0402\n",
      "Epoch 128/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0397\n",
      "Epoch 128: val_loss improved from 0.03990 to 0.03968, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 69ms/step - loss: 0.0398 - val_loss: 0.0397\n",
      "Epoch 129/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0398\n",
      "Epoch 129: val_loss did not improve from 0.03968\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.0398 - val_loss: 0.0399\n",
      "Epoch 130/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0397\n",
      "Epoch 130: val_loss did not improve from 0.03968\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.0397 - val_loss: 0.0400\n",
      "Epoch 131/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0397\n",
      "Epoch 131: val_loss improved from 0.03968 to 0.03947, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 70ms/step - loss: 0.0397 - val_loss: 0.0395\n",
      "Epoch 132/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0397\n",
      "Epoch 132: val_loss did not improve from 0.03947\n",
      "78/78 [==============================] - 5s 67ms/step - loss: 0.0397 - val_loss: 0.0397\n",
      "Epoch 133/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0397\n",
      "Epoch 133: val_loss did not improve from 0.03947\n",
      "78/78 [==============================] - 5s 66ms/step - loss: 0.0397 - val_loss: 0.0396\n",
      "Epoch 134/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0387\n",
      "Epoch 134: val_loss improved from 0.03947 to 0.03849, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 65ms/step - loss: 0.0387 - val_loss: 0.0385\n",
      "Epoch 135/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0386\n",
      "Epoch 135: val_loss improved from 0.03849 to 0.03845, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 64ms/step - loss: 0.0386 - val_loss: 0.0384\n",
      "Epoch 136/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 136: val_loss did not improve from 0.03845\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0386 - val_loss: 0.0385\n",
      "Epoch 137/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 137: val_loss did not improve from 0.03845\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0386 - val_loss: 0.0386\n",
      "Epoch 138/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0386\n",
      "Epoch 138: val_loss did not improve from 0.03845\n",
      "78/78 [==============================] - 5s 61ms/step - loss: 0.0386 - val_loss: 0.0385\n",
      "Epoch 139/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0385\n",
      "Epoch 139: val_loss improved from 0.03845 to 0.03842, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 64ms/step - loss: 0.0385 - val_loss: 0.0384\n",
      "Epoch 140/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 140: val_loss did not improve from 0.03842\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0385 - val_loss: 0.0385\n",
      "Epoch 141/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0386\n",
      "Epoch 141: val_loss did not improve from 0.03842\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0385 - val_loss: 0.0384\n",
      "Epoch 142/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 142: val_loss did not improve from 0.03842\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0385 - val_loss: 0.0385\n",
      "Epoch 143/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 143: val_loss improved from 0.03842 to 0.03838, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel.h5\n",
      "78/78 [==============================] - 5s 64ms/step - loss: 0.0386 - val_loss: 0.0384\n",
      "Epoch 144/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0385\n",
      "Epoch 144: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0385 - val_loss: 0.0385\n",
      "Epoch 145/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0386\n",
      "Epoch 145: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 61ms/step - loss: 0.0386 - val_loss: 0.0386\n",
      "Epoch 146/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 146: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 61ms/step - loss: 0.0385 - val_loss: 0.0386\n",
      "Epoch 147/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0387\n",
      "Epoch 147: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0387 - val_loss: 0.0385\n",
      "Epoch 148/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 148: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0385 - val_loss: 0.0386\n",
      "Epoch 149/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0386\n",
      "Epoch 149: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0386 - val_loss: 0.0387\n",
      "Epoch 150/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0386\n",
      "Epoch 150: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 62ms/step - loss: 0.0386 - val_loss: 0.0385\n",
      "Epoch 151/400\n",
      "77/78 [============================>.] - ETA: 0s - loss: 0.0386\n",
      "Epoch 151: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 63ms/step - loss: 0.0385 - val_loss: 0.0386\n",
      "Epoch 152/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 152: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 63ms/step - loss: 0.0385 - val_loss: 0.0384\n",
      "Epoch 153/400\n",
      "78/78 [==============================] - ETA: 0s - loss: 0.0385\n",
      "Epoch 153: val_loss did not improve from 0.03838\n",
      "78/78 [==============================] - 5s 65ms/step - loss: 0.0385 - val_loss: 0.0386\n"
     ]
    }
   ],
   "source": [
    "hist = autoencoder.fit(x_train_reshaped, x_train_reshaped,\n",
    "                epochs=400, batch_size=10,\n",
    "                shuffle=True,\n",
    "                validation_data=(x_valid_reshaped, x_valid_reshaped),\n",
    "                callbacks = callbacksList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f2b33bffd0>"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(hist.history['loss'])\n",
    "plt.plot(hist.history['val_loss'])\n",
    "plt.legend(['loss', 'val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F37792B370>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F37792B370>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dense.Dense object at 0x000001F37792B850>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.core.dense.Dense object at 0x000001F37792B850>, because it is not built.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F388303460>, because it is not built.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Skipping full serialization of Keras layer <keras.layers.regularization.dropout.Dropout object at 0x000001F388303460>, because it is not built.\n",
      "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 8). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel\\assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderOnlineDataModel\\assets\n"
     ]
    }
   ],
   "source": [
    "\n",
    "autoencoder.save(filepath+'\\\\models\\\\autoencoderOnlineDataModel')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"autoencoder_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " my_encoder_10 (MyEncoder)   multiple                  2904744   \n",
      "                                                                 \n",
      " my_decoder_10 (MyDecoder)   multiple                  4233064   \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,137,808\n",
      "Trainable params: 7,137,552\n",
      "Non-trainable params: 256\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "autoencoder.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## append an MLP to the trained encoder\n",
    "\n",
    "(Brain Surgery) <br>\n",
    "\n",
    "Clip off the encoder part of the neural network<br>\n",
    "Freeze the lower convoluutional layers<br>\n",
    "\n",
    "Connect to another couple of fully connected layers<br>\n",
    "Only train those last few layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder_loaded = tf.keras.models.load_model(filepath+'\\\\models\\\\autoencoderOnlineDataModel')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze encoder and add an MLP to the output of the encoder in another network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001F3824ACC40>\n",
      "False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001F377936550>\n",
      "False\n",
      "<keras.layers.regularization.spatial_dropout1d.SpatialDropout1D object at 0x000001F377812850>\n",
      "False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001F377812310>\n",
      "False\n",
      "<keras.layers.pooling.average_pooling1d.AveragePooling1D object at 0x000001F3778123A0>\n",
      "False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001F37781C580>\n",
      "False\n",
      "<keras.layers.regularization.spatial_dropout1d.SpatialDropout1D object at 0x000001F377812070>\n",
      "False\n",
      "<keras.layers.reshaping.flatten.Flatten object at 0x000001F37781CEE0>\n",
      "False\n",
      "<keras.layers.core.dense.Dense object at 0x000001F382594A30>\n",
      "True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x000001F37C1D7BE0>\n",
      "True\n",
      "<keras.layers.core.dense.Dense object at 0x000001F37781CD90>\n",
      "True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x000001F3826218E0>\n",
      "True\n",
      "<keras.layers.core.dense.Dense object at 0x000001F3826213D0>\n",
      "True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x000001F382621A90>\n",
      "True\n",
      "<keras.layers.core.dense.Dense object at 0x000001F382621DC0>\n",
      "True\n",
      "Model: \"sequential_9\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d_68 (Conv1D)          (None, 640, 32)           1312      \n",
      "                                                                 \n",
      " conv1d_69 (Conv1D)          (None, 621, 32)           20512     \n",
      "                                                                 \n",
      " spatial_dropout1d_54 (Spati  (None, 621, 32)          0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " conv1d_70 (Conv1D)          (None, 616, 32)           6176      \n",
      "                                                                 \n",
      " average_pooling1d_27 (Avera  (None, 308, 32)          0         \n",
      " gePooling1D)                                                    \n",
      "                                                                 \n",
      " conv1d_71 (Conv1D)          (None, 303, 32)           6176      \n",
      "                                                                 \n",
      " spatial_dropout1d_55 (Spati  (None, 303, 32)          0         \n",
      " alDropout1D)                                                    \n",
      "                                                                 \n",
      " flatten_27 (Flatten)        (None, 9696)              0         \n",
      "                                                                 \n",
      " dense_108 (Dense)           (None, 296)               2870312   \n",
      "                                                                 \n",
      " dropout_70 (Dropout)        (None, 296)               0         \n",
      "                                                                 \n",
      " dense_109 (Dense)           (None, 148)               43956     \n",
      "                                                                 \n",
      " dropout_71 (Dropout)        (None, 148)               0         \n",
      "                                                                 \n",
      " dense_110 (Dense)           (None, 74)                11026     \n",
      "                                                                 \n",
      " dropout_72 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_111 (Dense)           (None, 4)                 300       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,959,770\n",
      "Trainable params: 2,925,594\n",
      "Non-trainable params: 34,176\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "NewNet = tf.keras.Sequential()\n",
    "for layer in autoencoder.encoder.layers[:-1]:\n",
    "    layer.trainable = False\n",
    "    NewNet.add(layer)\n",
    "drop_rate = 0.5\n",
    "NewNet.add(tf.keras.layers.Dense(296, activation='relu'))\n",
    "NewNet.add(tf.keras.layers.Dropout(drop_rate))\n",
    "NewNet.add(tf.keras.layers.Dense(148, activation='relu'))\n",
    "NewNet.add(tf.keras.layers.Dropout(drop_rate))\n",
    "NewNet.add(tf.keras.layers.Dense(74, activation='relu'))\n",
    "NewNet.add(tf.keras.layers.Dropout(drop_rate))\n",
    "NewNet.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "# check trainablitity\n",
    "\n",
    "for layer in NewNet.layers:\n",
    "    print(layer)\n",
    "    print(layer.trainable)\n",
    "\n",
    "NewNet.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "\n",
    "NewNet.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "# Where to save model\n",
    "modelPath = filepath + r'\\models\\autoencoderMlpModel.h5'\n",
    "\n",
    "# build callback list\n",
    "checkpoint = ModelCheckpoint( # set model saving checkpoints\n",
    "    modelPath, # set path to save model weights\n",
    "    monitor='val_loss', # set monitor metrics\n",
    "    verbose=1, # set training verbosity\n",
    "    save_best_only=True, # set if want to save only best weights\n",
    "    save_weights_only=True, # set if you want to save only model weights\n",
    "    mode='auto', # set if save min or max in metrics\n",
    "    save_freq='epoch' # interval between checkpoints\n",
    "    )\n",
    "\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss', # set monitor metrics\n",
    "    min_delta=0.00001, # set minimum metrics delta\n",
    "    patience=6, # number of epochs to stop training\n",
    "    restore_best_weights=True, # set if use best weights or last weights\n",
    "    )\n",
    "callbacksList = [checkpoint, earlystopping] # build callbacks list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "90/91 [============================>.] - ETA: 0s - loss: 1.3854 - accuracy: 0.2489\n",
      "Epoch 1: val_loss improved from inf to 1.38630, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\models\\autoencoderMlpModel.h5\n",
      "91/91 [==============================] - 6s 41ms/step - loss: 1.3854 - accuracy: 0.2500 - val_loss: 1.3863 - val_accuracy: 0.2492\n",
      "Epoch 2/100\n",
      "90/91 [============================>.] - ETA: 0s - loss: 1.3877 - accuracy: 0.2589\n",
      "Epoch 2: val_loss did not improve from 1.38630\n",
      "91/91 [==============================] - 4s 40ms/step - loss: 1.3878 - accuracy: 0.2588 - val_loss: 1.3863 - val_accuracy: 0.2492\n",
      "Epoch 3/100\n",
      "90/91 [============================>.] - ETA: 0s - loss: 1.3858 - accuracy: 0.2478\n",
      "Epoch 3: val_loss did not improve from 1.38630\n",
      "91/91 [==============================] - 4s 49ms/step - loss: 1.3858 - accuracy: 0.2478 - val_loss: 1.3863 - val_accuracy: 0.2492\n",
      "Epoch 4/100\n",
      "90/91 [============================>.] - ETA: 0s - loss: 1.3874 - accuracy: 0.2489\n",
      "Epoch 4: val_loss did not improve from 1.38630\n",
      "91/91 [==============================] - 3s 34ms/step - loss: 1.3876 - accuracy: 0.2467 - val_loss: 1.3863 - val_accuracy: 0.2492\n",
      "Epoch 5/100\n",
      "89/91 [============================>.] - ETA: 0s - loss: 1.3875 - accuracy: 0.2393\n",
      "Epoch 5: val_loss did not improve from 1.38630\n",
      "91/91 [==============================] - 3s 35ms/step - loss: 1.3875 - accuracy: 0.2401 - val_loss: 1.3864 - val_accuracy: 0.2591\n",
      "Epoch 6/100\n",
      "90/91 [============================>.] - ETA: 0s - loss: 1.3856 - accuracy: 0.2722\n",
      "Epoch 6: val_loss did not improve from 1.38630\n",
      "91/91 [==============================] - 3s 34ms/step - loss: 1.3854 - accuracy: 0.2720 - val_loss: 1.3863 - val_accuracy: 0.2359\n",
      "Epoch 7/100\n",
      "90/91 [============================>.] - ETA: 0s - loss: 1.3860 - accuracy: 0.2478\n",
      "Epoch 7: val_loss did not improve from 1.38630\n",
      "91/91 [==============================] - 3s 33ms/step - loss: 1.3859 - accuracy: 0.2467 - val_loss: 1.3863 - val_accuracy: 0.2381\n"
     ]
    }
   ],
   "source": [
    "hist = NewNet.fit(x_test_reshaped, y_test_OH, epochs=100, batch_size=10,\n",
    "                    validation_data=(x_valid_reshaped, y_valid_OH), callbacks=callbacksList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f3add9cac0>"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(hist.history['accuracy'], color = 'b')\n",
    "ax.plot(hist.history['val_accuracy'], linestyle=':', color = 'b')\n",
    "ax.set_ylabel(\"Accuracy\", color = 'b')\n",
    "ax.set_ylim([0,1])\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(hist.history['loss'],  color = 'r')\n",
    "ax2.plot(hist.history['val_loss'], linestyle=':',  color = 'r')\n",
    "ax2.set_ylabel(\"Loss (cross-entropy)\",  color = 'r')\n",
    "fig.legend(['accuracy','val_accuracy','loss','val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainedModel_loaded = tf.keras.models.load_model(filepath + '\\\\models\\\\roi_b')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Replace the output layer for 4 rather than 5 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 640, 32)           1312      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 640, 32)          128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 621, 32)           20512     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 621, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 621, 32)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 616, 32)           6176      \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 308, 32)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 303, 32)           6176      \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 303, 32)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9696)              0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 296)               2870312   \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 296)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 148)               43956     \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 148)               0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 74)                11026     \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 4)                 300       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,960,026\n",
      "Trainable params: 2,959,898\n",
      "Non-trainable params: 128\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "trainedModel_newLayers = tf.keras.Sequential()\n",
    "for layer in trainedModel_loaded.layers[:10]: # go through until flatten layer\n",
    "    trainedModel_newLayers.add(layer)\n",
    "\n",
    "trainedModel_newLayers.add(tf.keras.layers.Dense(296, activation='relu'))\n",
    "trainedModel_newLayers.add(tf.keras.layers.Dropout(0.5))\n",
    "trainedModel_newLayers.add(tf.keras.layers.Dense(148, activation='relu'))\n",
    "trainedModel_newLayers.add(tf.keras.layers.Dropout(0.5))\n",
    "trainedModel_newLayers.add(tf.keras.layers.Dense(74, activation='relu'))\n",
    "trainedModel_newLayers.add(tf.keras.layers.Dropout(0.5))\n",
    "trainedModel_newLayers.add(tf.keras.layers.Dense(4, activation='softmax'))\n",
    "\n",
    "trainedModel_newLayers.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Freeze the first few convolutional layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001F3ADDF6760>\n",
      "Trainable? False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3ADDFEFA0>\n",
      "Trainable? False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001F3ADE1A910>\n",
      "Trainable? False\n",
      "<keras.layers.normalization.batch_normalization.BatchNormalization object at 0x000001F3ADE1AFD0>\n",
      "Trainable? False\n",
      "<keras.layers.regularization.spatial_dropout1d.SpatialDropout1D object at 0x000001F3ADE21040>\n",
      "Trainable? False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001F3ADE21CA0>\n",
      "Trainable? False\n",
      "<keras.layers.pooling.average_pooling1d.AveragePooling1D object at 0x000001F3ADE29400>\n",
      "Trainable? False\n",
      "<keras.layers.convolutional.conv1d.Conv1D object at 0x000001F3ADE296D0>\n",
      "Trainable? False\n",
      "<keras.layers.regularization.spatial_dropout1d.SpatialDropout1D object at 0x000001F3ADE29DF0>\n",
      "Trainable? False\n",
      "<keras.layers.reshaping.flatten.Flatten object at 0x000001F3ADE29FA0>\n",
      "Trainable? False\n",
      "<keras.layers.core.dense.Dense object at 0x000001F3ADE3CAC0>\n",
      "Trainable? True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x000001F3ADDA1EE0>\n",
      "Trainable? True\n",
      "<keras.layers.core.dense.Dense object at 0x000001F3ADE3C100>\n",
      "Trainable? True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x000001F3B38D1E50>\n",
      "Trainable? True\n",
      "<keras.layers.core.dense.Dense object at 0x000001F3B387ECD0>\n",
      "Trainable? True\n",
      "<keras.layers.regularization.dropout.Dropout object at 0x000001F3B387EB80>\n",
      "Trainable? True\n",
      "<keras.layers.core.dense.Dense object at 0x000001F3ADE218E0>\n",
      "Trainable? True\n",
      "Model: \"sequential_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv1d (Conv1D)             (None, 640, 32)           1312      \n",
      "                                                                 \n",
      " batch_normalization (BatchN  (None, 640, 32)          128       \n",
      " ormalization)                                                   \n",
      "                                                                 \n",
      " conv1d_1 (Conv1D)           (None, 621, 32)           20512     \n",
      "                                                                 \n",
      " batch_normalization_1 (Batc  (None, 621, 32)          128       \n",
      " hNormalization)                                                 \n",
      "                                                                 \n",
      " spatial_dropout1d (SpatialD  (None, 621, 32)          0         \n",
      " ropout1D)                                                       \n",
      "                                                                 \n",
      " conv1d_2 (Conv1D)           (None, 616, 32)           6176      \n",
      "                                                                 \n",
      " average_pooling1d (AverageP  (None, 308, 32)          0         \n",
      " ooling1D)                                                       \n",
      "                                                                 \n",
      " conv1d_3 (Conv1D)           (None, 303, 32)           6176      \n",
      "                                                                 \n",
      " spatial_dropout1d_1 (Spatia  (None, 303, 32)          0         \n",
      " lDropout1D)                                                     \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 9696)              0         \n",
      "                                                                 \n",
      " dense_112 (Dense)           (None, 296)               2870312   \n",
      "                                                                 \n",
      " dropout_73 (Dropout)        (None, 296)               0         \n",
      "                                                                 \n",
      " dense_113 (Dense)           (None, 148)               43956     \n",
      "                                                                 \n",
      " dropout_74 (Dropout)        (None, 148)               0         \n",
      "                                                                 \n",
      " dense_114 (Dense)           (None, 74)                11026     \n",
      "                                                                 \n",
      " dropout_75 (Dropout)        (None, 74)                0         \n",
      "                                                                 \n",
      " dense_115 (Dense)           (None, 4)                 300       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,960,026\n",
      "Trainable params: 2,925,594\n",
      "Non-trainable params: 34,432\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "for i in range(10):\n",
    "    trainedModel_newLayers.layers[i].trainable = False\n",
    "\n",
    "for layer in trainedModel_newLayers.layers:\n",
    "    print(layer)\n",
    "    print('Trainable? ' + str(layer.trainable))\n",
    "\n",
    "trainedModel_newLayers.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving to: c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "Epoch 1/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.4105 - accuracy: 0.2558\n",
      "Epoch 1: val_loss improved from inf to 1.38740, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 7s 56ms/step - loss: 1.4109 - accuracy: 0.2548 - val_loss: 1.3874 - val_accuracy: 0.2588\n",
      "Epoch 2/100\n",
      "76/78 [============================>.] - ETA: 0s - loss: 1.3908 - accuracy: 0.2711\n",
      "Epoch 2: val_loss improved from 1.38740 to 1.38642, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 4s 45ms/step - loss: 1.3919 - accuracy: 0.2703 - val_loss: 1.3864 - val_accuracy: 0.2731\n",
      "Epoch 3/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3848 - accuracy: 0.2844\n",
      "Epoch 3: val_loss improved from 1.38642 to 1.38529, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 4s 50ms/step - loss: 1.3848 - accuracy: 0.2844 - val_loss: 1.3853 - val_accuracy: 0.2808\n",
      "Epoch 4/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.4000 - accuracy: 0.2584\n",
      "Epoch 4: val_loss improved from 1.38529 to 1.38433, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 3s 43ms/step - loss: 1.4013 - accuracy: 0.2561 - val_loss: 1.3843 - val_accuracy: 0.2720\n",
      "Epoch 5/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3802 - accuracy: 0.2805\n",
      "Epoch 5: val_loss improved from 1.38433 to 1.38231, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 4s 47ms/step - loss: 1.3807 - accuracy: 0.2806 - val_loss: 1.3823 - val_accuracy: 0.2775\n",
      "Epoch 6/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3604 - accuracy: 0.3013\n",
      "Epoch 6: val_loss improved from 1.38231 to 1.38124, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.3600 - accuracy: 0.3037 - val_loss: 1.3812 - val_accuracy: 0.2698\n",
      "Epoch 7/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3702 - accuracy: 0.2909\n",
      "Epoch 7: val_loss did not improve from 1.38124\n",
      "78/78 [==============================] - 3s 43ms/step - loss: 1.3702 - accuracy: 0.2909 - val_loss: 1.3813 - val_accuracy: 0.2830\n",
      "Epoch 8/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3589 - accuracy: 0.3230\n",
      "Epoch 8: val_loss improved from 1.38124 to 1.38059, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 3s 45ms/step - loss: 1.3589 - accuracy: 0.3230 - val_loss: 1.3806 - val_accuracy: 0.2643\n",
      "Epoch 9/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3615 - accuracy: 0.3338\n",
      "Epoch 9: val_loss improved from 1.38059 to 1.37963, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 3s 43ms/step - loss: 1.3610 - accuracy: 0.3359 - val_loss: 1.3796 - val_accuracy: 0.2830\n",
      "Epoch 10/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3439 - accuracy: 0.3273\n",
      "Epoch 10: val_loss improved from 1.37963 to 1.37897, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 4s 48ms/step - loss: 1.3444 - accuracy: 0.3269 - val_loss: 1.3790 - val_accuracy: 0.2896\n",
      "Epoch 11/100\n",
      "77/78 [============================>.] - ETA: 0s - loss: 1.3357 - accuracy: 0.3455\n",
      "Epoch 11: val_loss improved from 1.37897 to 1.37816, saving model to c:\\Users\\james\\OneDrive\\GradSchool\\Spring 2022\\tunedMode.h5\n",
      "78/78 [==============================] - 4s 54ms/step - loss: 1.3357 - accuracy: 0.3462 - val_loss: 1.3782 - val_accuracy: 0.2907\n",
      "Epoch 12/100\n",
      "76/78 [============================>.] - ETA: 0s - loss: 1.3296 - accuracy: 0.3553\n",
      "Epoch 12: val_loss did not improve from 1.37816\n",
      "78/78 [==============================] - 3s 44ms/step - loss: 1.3278 - accuracy: 0.3539 - val_loss: 1.3808 - val_accuracy: 0.2885\n",
      "Epoch 13/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3248 - accuracy: 0.3874\n",
      "Epoch 13: val_loss did not improve from 1.37816\n",
      "78/78 [==============================] - 3s 43ms/step - loss: 1.3248 - accuracy: 0.3874 - val_loss: 1.3816 - val_accuracy: 0.2896\n",
      "Epoch 14/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.3051 - accuracy: 0.3810\n",
      "Epoch 14: val_loss did not improve from 1.37816\n",
      "78/78 [==============================] - 3s 40ms/step - loss: 1.3051 - accuracy: 0.3810 - val_loss: 1.3801 - val_accuracy: 0.2941\n",
      "Epoch 15/100\n",
      "78/78 [==============================] - ETA: 0s - loss: 1.2861 - accuracy: 0.4286\n",
      "Epoch 15: val_loss did not improve from 1.37816\n",
      "78/78 [==============================] - 3s 39ms/step - loss: 1.2861 - accuracy: 0.4286 - val_loss: 1.3814 - val_accuracy: 0.2963\n"
     ]
    }
   ],
   "source": [
    "learning_rate = 1e-4\n",
    "\n",
    "loss = tf.keras.losses.categorical_crossentropy\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=learning_rate)\n",
    "modelPath = os.path.join(os.getcwd(), 'tunedMode.h5')\n",
    "print('Saving to: ' + modelPath)\n",
    "\n",
    "trainedModel_newLayers.compile(loss=loss, optimizer=optimizer, metrics=['accuracy'])\n",
    "\n",
    "checkpoint = ModelCheckpoint( # set model saving checkpoints\n",
    "    modelPath, # set path to save model weights\n",
    "    monitor='val_loss', # set monitor metrics\n",
    "    verbose=1, # set training verbosity\n",
    "    save_best_only=True, # set if want to save only best weights\n",
    "    save_weights_only=True, # set if you want to save only model weights\n",
    "    mode='auto', # set if save min or max in metrics\n",
    "    save_freq=\"epoch\"  # interval between checkpoints\n",
    "    )\n",
    "\n",
    "earlystopping = EarlyStopping(\n",
    "    monitor='val_loss', # set monitor metrics\n",
    "    min_delta=0.00001, # set minimum metrics delta\n",
    "    patience=4, # number of epochs to stop training\n",
    "    restore_best_weights=True, # set if use best weights or last weights\n",
    "    )\n",
    "callbacksList = [checkpoint, earlystopping] # build callbacks list\n",
    "\n",
    "hist = trainedModel_newLayers.fit(x_train_reshaped, y_train_OH_smote, epochs=100, batch_size=10,\n",
    "                validation_data=(x_test_reshaped, y_test_OH), callbacks=callbacksList) #32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1f3b6e139d0>"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig,ax=plt.subplots()\n",
    "ax.plot(hist.history['accuracy'], color = 'b')\n",
    "ax.plot(hist.history['val_accuracy'], linestyle=':', color = 'b')\n",
    "ax.set_ylabel(\"Accuracy\", color = 'b')\n",
    "ax.set_ylim([0,1])\n",
    "ax2=ax.twinx()\n",
    "ax2.plot(hist.history['loss'],  color = 'r')\n",
    "ax2.plot(hist.history['val_loss'], linestyle=':',  color = 'r')\n",
    "ax2.set_ylabel(\"Loss (cross-entropy)\",  color = 'r')\n",
    "fig.legend(['accuracy','val_accuracy','loss','val_loss'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluate final model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "29/29 [==============================] - 1s 20ms/step - loss: 1.3709 - accuracy: 0.3120\n",
      "\n",
      "Accuracy: 0.31201764941215515\n",
      "\n",
      "Loss:  1.3709309101104736\n",
      "29/29 [==============================] - 1s 16ms/step\n",
      "\n",
      " Cohen kappa \n",
      "\n",
      " 0.08258944853376216\n",
      "\n",
      " Classification report \n",
      "\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "       Right       0.29      0.32      0.30       227\n",
      "        Left       0.36      0.25      0.30       226\n",
      "        Rest       0.29      0.22      0.25       227\n",
      "      tongue       0.32      0.45      0.38       227\n",
      "\n",
      "    accuracy                           0.31       907\n",
      "   macro avg       0.31      0.31      0.31       907\n",
      "weighted avg       0.31      0.31      0.31       907\n",
      "\n",
      "\n",
      " Confusion matrix \n",
      "\n",
      " [[ 72  34  55  66]\n",
      " [ 55  57  35  79]\n",
      " [ 71  31  51  74]\n",
      " [ 51  37  36 103]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testLoss, testAcc = trainedModel_newLayers.evaluate(x_valid_reshaped, y_valid_OH)\n",
    "print('\\nAccuracy:', testAcc)\n",
    "print('\\nLoss: ', testLoss)\n",
    "\n",
    "from sklearn.metrics import classification_report, confusion_matrix, cohen_kappa_score\n",
    "yPred = trainedModel_newLayers.predict(x_valid_reshaped)\n",
    "\n",
    "# convert from one hot encode in string\n",
    "yTestClass = np.argmax(y_valid_OH, axis=1)\n",
    "yPredClass = np.argmax(yPred,axis=1)\n",
    "\n",
    "print('\\n Cohen kappa \\n\\n',\n",
    "  cohen_kappa_score(\n",
    "      yTestClass,\n",
    "      yPredClass\n",
    "      )\n",
    "  )\n",
    "\n",
    "print('\\n Classification report \\n\\n',\n",
    "  classification_report(\n",
    "      yTestClass,\n",
    "      yPredClass,\n",
    "       target_names=[\"Right\", \"Left\", \"Rest\", \"tongue\"]\n",
    "      )\n",
    "  )\n",
    "\n",
    "print('\\n Confusion matrix \\n\\n',\n",
    "  confusion_matrix(\n",
    "      yTestClass,\n",
    "      yPredClass,\n",
    "      )\n",
    "  )\n",
    "\n",
    "import seaborn as sns\n",
    "sns.heatmap(confusion_matrix(\n",
    "      yTestClass,\n",
    "      yPredClass,\n",
    "      ))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "2c47cab3ea366cb5a0e1d2e4dbca7e06cc3f3ddb05367e3852ec81be0ec0be64"
  },
  "kernelspec": {
   "display_name": "Python 3.8.13 ('tfgpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
